{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixa54roQ5oE3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgzVykXk5wnw",
        "outputId": "76b706b0-05ad-4804-ffc3-b76353e35580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the first object detection model\n",
        "PATH_TO_SAVED_MODEL1=\"/content/gdrive/MyDrive/customTF2/data/inference_graph/saved_model\"\n",
        "model1 = tf.saved_model.load(PATH_TO_SAVED_MODEL1)"
      ],
      "metadata": {
        "id": "s5PzPQlO5yCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the first object detection model\n",
        "PATH_TO_SAVED_MODEL2=\"/content/gdrive/MyDrive/fasterTF2/data/inference_graph/saved_model\"\n",
        "model2 = tf.saved_model.load(PATH_TO_SAVED_MODEL2)"
      ],
      "metadata": {
        "id": "YlxXx0rm56AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the directory path\n",
        "dir_path = '/content/gdrive/MyDrive/customTF2/test_images/'\n",
        "savepath = '/content/gdrive/MyDrive/Ensemble/detections/'\n",
        "labels = ['Handgun', 'Knife', 'RazorBlade', 'Shuriken']"
      ],
      "metadata": {
        "id": "bcPbIHLt6BNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through all the files in the directory\n",
        "for filename in os.listdir(dir_path):\n",
        "    # check if the file is an image\n",
        "    if filename.endswith('.png'):\n",
        "        # open the image file using PIL\n",
        "        image_path = os.path.join(dir_path, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "        image_np = np.array(image)\n",
        "\n",
        "        # Create the input tensor\n",
        "        input_tensor = tf.convert_to_tensor(image_np)\n",
        "        input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "        input_tensor = tf.image.convert_image_dtype(input_tensor, tf.uint8)\n",
        "\n",
        "        # Make predictions using the first model\n",
        "        outputs1 = model1(input_tensor)\n",
        "        boxes1 = outputs1['detection_boxes'].numpy()[0]\n",
        "        scores1 = outputs1['detection_scores'].numpy()[0]\n",
        "        classes1 = outputs1['detection_classes'].numpy()[0].astype(np.uint8)\n",
        "\n",
        "        # Make predictions using the second model\n",
        "        outputs2 = model2(input_tensor)\n",
        "        boxes2 = outputs2['detection_boxes'].numpy()[0]\n",
        "        scores2 = outputs2['detection_scores'].numpy()[0]\n",
        "        classes2 = outputs2['detection_classes'].numpy()[0].astype(np.uint8)\n",
        "\n",
        "        b1 = []\n",
        "        s1 = []\n",
        "        c1 = []\n",
        "        th = 0.5\n",
        "        for i in range(len(scores1)):\n",
        "          if scores1[i]>th:\n",
        "            b1.append(boxes1[i])\n",
        "            s1.append(scores1[i])\n",
        "            c1.append(classes1[i])\n",
        "        \n",
        "        b2 = []\n",
        "        s2 = []\n",
        "        c2 = []\n",
        "        for i in range(len(scores2)):\n",
        "          if scores2[i]>th:\n",
        "            b2.append(boxes2[i])\n",
        "            s2.append(scores2[i])\n",
        "            c2.append(classes2[i])\n",
        "        \n",
        "        boxes = []\n",
        "        scores = []\n",
        "        classes = []\n",
        "        for i in range(len(s1)):\n",
        "          if s1[i]>=s2[i]:\n",
        "            boxes.append(b1[i])\n",
        "            scores.append(s1[i])\n",
        "            classes.append(c1[i])\n",
        "          else:\n",
        "            boxes.append(b2[i])\n",
        "            scores.append(s2[i])\n",
        "            classes.append(c2[i])\n",
        "\n",
        "        detections = []\n",
        "        th = 0.5\n",
        "        H, W, _ = image.shape\n",
        "        # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
        "        for i in range(len(scores)):\n",
        "          if ((scores[i] > th) and (scores[i] <= 1.0)):\n",
        "            # Get bounding box coordinates and draw box\n",
        "            # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
        "            ymin = int(max(1,(boxes[i][0] * H)))\n",
        "            xmin = int(max(1,(boxes[i][1] * W)))\n",
        "            ymax = int(min(H,(boxes[i][2] * H)))\n",
        "            xmax = int(min(W,(boxes[i][3] * W)))\n",
        "\n",
        "            # Draw label\n",
        "            object_name = labels[int(classes[i])-1] # Look up object name from \"labels\" array using class index\n",
        "            detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
        "\n",
        "        # Get filenames and paths\n",
        "        image_fn = os.path.basename(image_path)      \n",
        "        base_fn, ext = os.path.splitext(image_fn)\n",
        "        txt_result_fn = base_fn +'.txt'\n",
        "        txt_savepath = os.path.join(savepath, txt_result_fn)\n",
        "\n",
        "        # Write results to text file\n",
        "        # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n",
        "        with open(txt_savepath,'w') as f:\n",
        "            for detection in detections:\n",
        "                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))"
      ],
      "metadata": {
        "id": "mmzUBzdr6aZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}